---
title: "Comandos do `R` utilizados nas aulas"
output:
  html_document:
    toc: true
    code_folding: show
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: no
---

```{r setup, include=FALSE, cache=FALSE}
#source("setup_knitr.R")
knitr::opts_chunk$set(echo = TRUE,
                      comment = NA,
                      warning = FALSE,
                      message = FALSE,
                      cache = TRUE)
library(tidyquant)
```


<br>
<br>
<br>





# Coleta de dados


![](img/R_SQL_AWS.png)

### Coletando dados do S3 AWS

```{r s3 ,eval = FALSE}
#### Carrega o pacote para acessar s3 da aws pelo R
library("aws.s3")

#### Credenciais para acessar o S3 na AWS
source('credentials.R')

#### Carregando os dados

save_object(object = 'PA_dataset_2020/PA_DATA.RData',
            bucket = 'machine-learning-laura',
            file = 'PA_DATA.RData',
            region = 'us-east-2')


dir()
load('PA_DATA.RData')
ls()
head(PA_DATA)
dim(PA_DATA)
```


### Coletando os dados do Athena - AWS


```{R,athena ,eval = FALSE}
### Athena - AWS

## ##### Usuário e senha do Athena AWS
source('credentials2.R')
#conexão via drive ODBC
#https://db.rstudio.com/dbi/
con <- DBI::dbConnect(
   odbc::odbc(),
   Driver             = "/opt/simba/athenaodbc/lib/64/libathenaodbc_sb64.so",
   S3OutputLocation   = "s3://aws.glue.configurations/history.people.old/query_results/",
   AwsRegion          = "us-east-1",
   AuthenticationType = "athena.barletta",
   Schema             = "history_people_old",
   UID                = user,
   PWD                = pass
   )

## Lista as tabelas
DBI::dbListTables(con)
# Lista os campos de uma determinada Tabela
DBI::dbListFields(con, "e12_medical_record")

#### Criando as consultas via SQL
df <- dplyr::tbl(con,
                 dplyr::sql("SELECT atendimento_id,
                             date,
                             alta_data,
                             alta_motivo,
                             data_entrada,
                             data_nasc,
                             paciente_id,
                             setor_id,
                             setor_nome,
                             sexo,
                             clinica,
                             convenio_nome,
                             doenca_id,
                             doenca_nome,
                             tipo_atendimento
                      FROM e12_medical_record as t1
                      LEFT JOIN e12_medical_record_doencas as t2
                      ON t1.oid = t2.oid LIMIT 100")
                 )
head(df)

class(df)

df <- data.frame(df)

dim(df)
names(df)
```

# Pré-processamento dos dados

### Carregando os dados - Dados de crédito

```{R dados}
library(scorecard)
library(tidyverse)

data('germancredit')
germancredit$ID <- 1:dim(germancredit)[1]
head(germancredit[,c(2,5,11,20:22)], n = 5)
```


### Carregando os dados - Dados de hospital


```{r hData}
url <- 'https://felipebarletta.github.io/DAEST/hospital.csv'
dados <- read.csv(url,
                  h = TRUE,
                  sep = '\t')
```

### Gráfico idade vs desfecho

```{r GraphAge}
library(ggplot2)
ggplot(dados, aes(idade, fill = alta.motivo, colour = alta.motivo)) +
    geom_density(alpha= 0.1, fill = 'white') +
  xlab('Idade em anos') +
  ylab('Densidade') +
  theme_tq()
```




### Criando uma nova característica - faixa etária
```{r,out.width='64%',faixa}

dados$faixa_etaria <- ifelse(dados$idade > 55,
                             ">55 anos",
                             "<=55 anos")
```

### Gráfico com a nova característica

```{r,out.width='64%',graphFaixa}
ggplot(dados,
       aes(y = factor(alta.motivo),
           x = idade,
           color = faixa_etaria)) +
  geom_jitter(alpha = 0.7,
              size = 1.5) +
  labs(x = "Idade em anos",
       y = "") +
  theme_tq()
```

### Tabela de frequência - alta vs faixa etária

```{r,out.width='64%',Tab1}
table(dados$alta.motivo,dados$faixa_etaria)
```


### Gráfico Temperatura do paciente vs desfecho

```{r,out.width='64%',tempGraph}
ggplot(dados,
       aes(y = factor(alta.motivo),
           x = temperatura,
           color = alta.motivo)) +
  geom_jitter(alpha = 0.7,
              size = 1.5) +
  labs(x = "Temperatura em graus Celsius",
       y = "") +
  theme_tq()

```


### Filtrando **out-lier** - Obtendo uma nova amostra

```{r,out.width='64%', newSample}

dados2 <- dados %>%
  filter(temperatura > 0)

ggplot(dados2,
       aes(y = factor(alta.motivo),
           x = temperatura,
           color = alta.motivo)) +
  geom_jitter(alpha = 0.7,
              size = 1.5) +
  labs(x = "Temperatura em graus Celsius",
       y = "") +
  theme_tq()
```

### Dados - hospital2

```{r ts1}
## Carregando os dados
load('dados3.RData')

## Formatando a data
dados3$data <- as.Date(dados3$date,
                       format = "%Y-%m-%d",
                       origin="2016-01-01")

## Filtrando apenas classes óbito(1)
dados4 <- dados3 %>%
  filter(alta.motivo == 1)
```

### Resumindo as quantidades de de óbito por dia

```{r tab2}

df <- data.frame(table(dados4$data))

colnames(df) <- c('Dia','Quantidade')
df$Dia <- as.Date(df$Dia,
                     format = "%Y-%m-%d",
                     origin="2016-01-01")

head(df)
```

### Gráfico temporal de óbitos diários

```{R Graphts1}
library(ggplot2)
library(cowplot)
library(timetk)
library(tidyquant)
library(tibbletime)

# Axis limits c(min, max)
min <- min(df$Dia)
max <- max(df$Dia)
seg <-as.Date(min+480)

df <- as_tbl_time(df,index = Dia)
#### zoom
v3 <- df %>%
      ggplot(aes(x=Dia, y=Quantidade)) +
      geom_line(color = palette_light()[[1]], alpha = 0.5, size=1) +
      geom_point(color = palette_light()[[1]]) +
      geom_smooth(method = "loess", span = 0.2, se = TRUE, colour='darkorange') +
      theme_tq() +
      labs(title = "",
        caption = "")  + xlab("Dias") + ylab("Quantidade de Óbitos")

v3



```


### Selecionando uma amostra para visualização melhor

```{R Graphts2}
#### zoom
v4 <- df %>%
      filter_time("2017-01-01" ~ "2018-12-31") %>%
      ggplot(aes(x=Dia, y=Quantidade)) +
      geom_line(color = palette_light()[[1]], alpha = 0.5, size=1) +
      geom_point(color = palette_light()[[1]]) +
      geom_smooth(method = "loess", span = 0.2, se = TRUE, colour='darkorange') +
      theme_tq() +
      labs(title = "01/01/2017 à 31/12/2018",
        caption = "")  +
   xlab("Dias") +
   ylab("Quantidade de Óbitos")

v4
```


### Crindo uma característica nova - Dias da semana

```{r week}
df$w <- weekdays(df$Dia)
```


### Selecionando pacientes com alta

```{r alta}
dados4 <- dados3 %>%
  filter(alta.motivo == 0)

df <- data.frame(table(dados4$data))

colnames(df) <- c('Dia','Quantidade')
df$Dia <- as.Date(df$Dia,
                     format = "%Y-%m-%d",
                     origin="2016-01-01")

# Axis limits c(min, max)
min <- min(df$Dia)
max <- max(df$Dia)
seg <-as.Date(min+480)

df <- as_tbl_time(df,index = Dia)
#### zoom
v3 <- df %>%
    filter_time("2017-01-01" ~ "2018-12-31") %>%
      ggplot(aes(x=Dia, y=Quantidade)) +
      geom_line(color = palette_light()[[1]], alpha = 0.5, size=1) +
      geom_point(color = palette_light()[[1]]) +
      geom_smooth(method = "loess", span = 0.2, se = TRUE, colour='darkorange') +
      theme_tq() +
      labs(title = "01/01/2017 à 31/12/2018",
        caption = "")  +
      xlab("Dias") +
      ylab("Quantidade de Alta")

v3

```


### Mediana da quantidade de alta vs dia da semana

```{r week2}
df$w <- weekdays(df$Dia)
tapply(df$Quantidade,df$w, median)

```



### Missing values (valores faltantes)

```{R missing}

library(DataExplorer)

plot_missing(dados[,3:8])

```


### Criando uma nova caractrística - variável dicotômica UTI/Enfermaria

```{r uti}
table(dados$setor)
dados$setor2 <- ifelse(dados$setor %in% c('UTIC',
                                          'UTIG',
                                          'UTIP'),
                       'UTI',
                       'Enfermaria')
table(dados$setor2)
```



```{R mis1}
dados2 <- dados %>%
  filter(temperatura > 0)


uti1 <- ggplot(dados2, aes(y = factor(setor2),
                           x = temperatura,
                           color = setor2)) +
         geom_jitter(alpha = 0.7, size = 1.5) +
         labs(x = "Temperatura em graus Celsius", y = "") +
         theme_tq()


idade2 <- dados2 %>%
    filter(!is.na(sat_o2))

uti2 <- ggplot(idade2, aes(y = factor(setor2), x = temperatura, color = setor2)) +
        geom_jitter(alpha = 0.7,size = 1.5) +
        labs(x = "Temperatura em graus Celsius", y = "") +
        theme_tq()

cowplot::plot_grid(uti1,
                   uti2,
                   labels = c('Com missing - sat_o2',
                              'Sem missing - sat-O2'))

```

### Distribuição do desfecho na **UTI**

#### Com missing - sat_o2
```{r tabmiss1}
round(prop.table(table(dados$alta.motivo[dados$setor2 == 'UTI'])),4)
```
#### Sem missing - sat_o2
```{r tabmiss2}
round(prop.table(table(idade2$alta.motivo[idade2$setor2 == 'UTI'])),4)
```

### Exemplo - dados faltantes

```{R out.width='100%', missigTemp}

p1 <- ggplot(dados, aes(temperatura, fill = alta.motivo, colour = alta.motivo)) +
      geom_density(alpha= 0.1, fill = 'white') +
      xlab('Temperatura em graus Celsius') +
      ylab('Densidade') +
      theme_tq()

idade2 <- dados %>%
    filter(!is.na(sat_o2))

p2 <- ggplot(idade2, aes(temperatura, fill = alta.motivo, colour = alta.motivo)) +
      geom_density(alpha= 0.1, fill = 'white') +
      xlab('Temperatura em graus Celsius') +
      ylab('Densidade') +
      theme_tq()

cowplot::plot_grid(p1,
                   p2,
                   labels = c('Com missing',
                              'Sem missing'))
```




# Imputação

- Algoritmo **KNN** *(k-nearest neighbors)*

1. Recebe um dado não classificado;

2. Define o tamanho da vizinhança (K);

3. Mede a distância (Euclidiana) do novo; dado com todos os outros dados que já estão classificados;

4. Obtém a menor ou menores distâncias;

5. Verifica o valor de cada da um dos dados que tiveram a menor distância;

6. Toma como resultado o valor que mais apareceu dentre os dados que tiveram as menores distâncias.



```{r imp1}
library(caret)
missingdata <- preProcess(dados, method=c('scale','knnImpute'))


library(RANN)  # library for knnInpute
NewData <- predict(missingdata,
                     newdata = dados)
#anyNA(NewData)

p1 <- ggplot(dados, aes(temperatura, fill = alta.motivo, colour = alta.motivo)) +
    geom_density(alpha= 0.1, fill = 'white') +
    xlab('Temperatura em graus Celsius') +
    ylab('Densidade') +
    theme_tq()


p2 <- ggplot(NewData, aes(temperatura, fill = alta.motivo, colour = alta.motivo)) +
    geom_density(alpha= 0.1, fill = 'white') +
    xlab('Temperatura em graus Celsius') +
    ylab('Densidade') +
    theme_tq()

cowplot::plot_grid(p1,
                   p2,
                   labels = c('Com missing',
                              'Sem missing'))
```


### Dados desbalanceados

```{R credito}
ggplot(germancredit, aes(creditability)) +
  geom_bar() +
   theme_tq()

```

```{R saude}
ggplot(dados, aes(alta.motivo)) +
  geom_bar()+
   theme_tq()
```


# Correlação

- Exemplos de correlação

```{R corr}
# Diagrama de dispersão
# Plotando todos no mesmo gráfico
par(mfrow=c(2,3))
# Correlação perfeita positiva
x<-seq(-100, 100)
y1<-x*2.53
plot(x, y1, main = "Correlação perfeita positiva",ylab = "y",col="blue")

# Correlação perfeita negativa
x<-seq(-100, 100)
y2<- -x*2.53
plot(x, y2, main = "Correlação perfeita negativa",ylab = "y",col="blue")

# Alta correlação positiva
y3<-rnorm(y1,y1,20)
plot(x,y3,main="Alta correlação positiva",ylab = "y",col="blue")

# Alta correlação
y4<-rnorm(y1,(-1)*y1,20)
plot(x,y4,main="Alta correlação negativa",ylab = "y",col="blue")

# Baixa correlação positiva
y5<-rnorm(y1,y1,500)
plot(x,y5,main="Baixa correlação",ylab = "y",col="blue")

# Correlação não linear
y6<- rnorm(x, x^2, 1000)
plot(x,y6,main="Correlação não linear",ylab = "y",col="blue")

```


#### Matriz de correlação


```{R matrixCorr}
x <- dados[,c(1,3:8)]

#corrplot::corrplot(cor(na.omit(x)), method = 'number',type='upper')

cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(na.omit(x))
#head(p.mat[, 1:5])

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot::corrplot(cor(na.omit(x)), method="color", col=col(200),
         type="upper", order="hclust",
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.05, insig = "blank",
         # hide correlation coefficient on the principal diagonal
         diag=FALSE
         )

```

# Análise de Componentes principais

- Suponha um vetor de características  $X_1, X_2,...,X_p$

  $$Z_k = \phi_{1k}X_1 + \phi_{2k}X_2 +...+ \phi_{pk}X_p$$

- A variância total dos dados é definida como:

  $$\displaystyle{\sum_{j=1}^p}Var(Z_j) = \lambda_1+\lambda_2+...+\lambda_p$$

- Assim, a proporção da variância explicada pela j-ésima componente principal é dada por:

  $$ \displaystyle{\frac{\lambda_j}{\lambda_1+\lambda_2+...+\lambda_j}}$$



- Os dados usados nesse exemplo podem ser encontrados em [https://github.com/laura-health/cbms2020](https://github.com/laura-health/cbms2020)
```{r pca}

dados <- read.csv('heg_sample_data.csv',
                  header = TRUE,
                  sep = ',')

dim(dados)
head(dados[,1:6])

library(dplyr)

dados2  <- dados %>%
    select(-c('X',
              'document.sexo',
              'UTI',
              'outcome')
           )


#### Matriz de covariância
S <- round(cov(dados2),2)
dim(S)
S[1:3,1:3]

#### Matriz de correlação
R <- round(cor(dados2),2)
dim(R)
R[1:5,1:5]


### Gráfico da matriz de correlação
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(dados2)
#head(p.mat[, 1:5])

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot::corrplot(cor(dados2), method="color", col=col(200),
                   type="upper", order="hclust",
                   number.cex = .07,
                   tl.cex = 0.4,
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.05, insig = "blank",
         # hide correlation coefficient on the principal diagonal
         diag=FALSE
         )

### Padronizando
z <- scale(dados2)
#R <- round(cor(z),2)

# Autovalores e autovetores
autovalor.autovetor<- eigen(R)
head(autovalor.autovetor$vectors)

head(autovalor.autovetor$values)

# Recebendo percentual das variâncias e porcentagem acumulativa
var.porc  <-  autovalor.autovetor$values / sum(autovalor.autovetor$values)*100
head(var.porc)

var.acum  <- cumsum(var.porc)
head(var.acum)


porc.explic <- round(data.frame(autovalores = autovalor.autovetor$values,
                                var.porc = var.porc,
                                var.acum = var.acum), 3)

head(porc.explic,28)

plot(porc.explic$autovalores,
     type = "b",
     ylab = "Valor Autovalores",
     xlab = "Número de autovalores",
     axes = T)

abline(h=1, col=2, lwd=2)

# Matriz e dos coeficientes das combinações lineares referentes às componentes principais Yk

e <- round(as.matrix(autovalor.autovetor$vector),3)
head(e)

e[c(1:3,28),c(1:3,28)]


## C1 = -0.051*z1  -0.102*z2 -0.04*z3 ...-0.336*z28

## C28 = -0.336*z1 + 0.011+z2 .....-0.013*z28

V <- round(diag(autovalor.autovetor$values),3)
head(V)

escores <- round(t(e) %*% t(z),2)
dim(t(escores))
head(escores[,1:6])

plot(escores[2,] ~ escores[1,], cex = 0.7,
     main = "Gráfico dos escores da PC1 e PC2")

plot(escores[1,] ~ z[,1], cex = 0.7,
     main = "Gráfico dos escores da PC1 e com z1")

plot(escores[1,] ~ z[,2], cex = 0.7,
     main = "Gráfico dos escores da PC1 e com z2")


#### Função do R
PCA <- prcomp(dados2,
              scale = TRUE)
names(PCA)

PCA$sdev^2

head(PCA$rotation)

summary(PCA)

biplot(princomp(dados2, cor = T),
       pc.biplot = T, cex = 0.8, expand = )

```



# Método *K-means*


Para baizar os dados utilizados nesse exemplo, acesse [https://github.com/stedy/Machine-Learning-with-R-datasets](https://github.com/stedy/Machine-Learning-with-R-datasets) ou baixe da aba dados.



```{R kmeans}

dados <- read.csv('snsdata.csv',
                  h = TRUE)
head(dados)
dim(dados)
str(dados)

### Verificando valores faltantes
library(DataExplorer)
plot_missing(dados)


## Resumo da idade
summary(dados$age)

## Criando uma nova feature
dados$age <- ifelse(dados$age >= 13 & dados$age < 20,
                    dados$age, NA)

summary(dados$age)

## Resumo do gênero
table(dados$gender,
      useNA = 'ifany')

## Criando uma nova característica
dados$no_gender <- ifelse(is.na(dados$gender),
                          1, 0)

dados$female <- ifelse(dados$gender == "F" &
                       !is.na(dados$gender),
                       1, 0)

## Imputação
aggregate(data = dados,
          age ~ gradyear,
          mean,
          na.rm = TRUE)

## Criando uma nova característica
ave_age <- ave(dados$age,
               dados$gradyear,
               FUN = function(x) mean(x, na.rm = TRUE))

summary(ave_age)

dados$age <- ifelse(is.na(dados$age),
                    ave_age, dados$age)


## Selecionando apenas features numéricas
df <- dados[5:40]


## Padronizando
df_z <- as.data.frame(lapply(df, scale))


## Dividindo em 5 clusters
teen_clusters <- kmeans(x = df_z,
                        centers = 5)

# Avaliando os clusters
teen_clusters$size

teen_clusters$centers[,1:5]



### Atribuindo os clusters
dados$cluster <- teen_clusters$cluster

##
dados[1:5, c("cluster", "gender", "age", "friends")]

## Agregando as características demográficas
aggregate(data = dados,
          age ~ cluster,
          mean)

table(dados$gender, dados$cluster)

aggregate(data = dados,
          female ~ cluster,
          mean)

aggregate(data = dados,
          friends ~ cluster,
          mean)

```


# Aprendizado supervisionado

## Problema de classificação binária

```{r binomial}
rm(list=ls())
library(dplyr)
dados <- read.csv('hospital.csv',
                  h = TRUE,
                  sep = '\t')

dados$alta.motivo2 <- ifelse(dados$alta.motivo == "Obito",
                            1,0)
dados$alta.motivo2 <- as.factor(dados$alta.motivo2)

### criando novas características
dados$faixa_etaria <- ifelse(dados$idade > 55,
                             ">55 anos",
                             "<=55 anos")


dados$setor2 <- ifelse(dados$setor %in% c('UTIC',
                                          'UTIG',
                                          'UTIP'),
                       'UTI',
                       'Enfermaria')

### filtrando temperatura inconsistente
dados2 <- dados %>%
  filter(temperatura > 0)

##### Imputação
library(caret)
missingdata <- preProcess(dados2, method=c('scale','knnImpute'))


library(RANN)  # library for knnInpute
NewData <- predict(missingdata,
                     newdata = dados2)

##### Partição dos dados
set.seed(12339)
intrain <- caret::createDataPartition(y = NewData$alta.motivo,
                                      p = 0.75,
                                      list = FALSE)
train <- NewData[intrain, ]
test <- NewData[-intrain, ]

# Parametriza a valiação cruzada.
cv <- caret::trainControl(method = "repeatedcv",
                          number = 2,
                          repeats = 2,
                          classProbs = T,
                          search = "random",
                          savePredictions = 'final')


######### Regressão Logística
set.seed(19991233)
bin <- caret::train(alta.motivo ~ freq_respiratoria +
                        pa_diastolica +
                        pa_sistolica +
                        sat_o2 +
                        temperatura +
                        faixa_etaria +
                        setor2,
                    data = train,
                    method = "glm",
                    trControl = cv,
                    tuneLength = 5,
                    metric = 'logLoss')

bin
bin$finalModel

y1 <- predict(bin,
              newdata = test)

M_logistic <- confusionMatrix(y1,
                              test$alta.motivo,
                              positive = 'Obito')

varimp <- varImp(bin)
plot(varimp, main="Variable Importance")


##### Ávore de decisão
tree1 <- rpart::rpart(alta.motivo ~ freq_respiratoria +
                          pa_diastolica +
                          pa_sistolica +
                          sat_o2 +
                          temperatura +
                          faixa_etaria +
                          setor2,
                      data = train,
                      method="class",
                      parms = list(split = "information",prior=c(.55,.45)),
                      maxdepth=5)

rattle::fancyRpartPlot(tree1, palettes = c('Greens','Reds'))

y <- predict(tree1,
             newdata = test,
             type = 'class')

M_tree <- confusionMatrix(y,
                          test$alta.motivo,
                          positive = 'Obito')

predictions_prob <- predict(tree1,
             newdata = test,
             type = 'prob')

test$predictions_prob <- predictions_prob[,1]

test$Y <- ifelse(test$alta.motivo == 'Melhorado',1,
                 0)
test$Y <- as.factor(test$Y)




######## Random Forest
rf <- caret::train(alta.motivo ~ freq_respiratoria +
                       pa_diastolica +
                       pa_sistolica +
                       sat_o2 +
                       temperatura +
                       faixa_etaria +
                       setor2,
                   data = train,
                   method = "rf",
                   trControl = cv,
                   tuneLength = 5,
                   metric = 'logLoss')

rf
rf$finalModel

y2 <- predict(rf,
              newdata = test)

M_rf <- confusionMatrix(y2,
                        test$alta.motivo,
                        positive = 'Obito')

varimp <- varImp(rf)
plot(varimp, main="Variable Importance")



######### Gradient Boosting Machine
gbm <- caret::train(alta.motivo ~ freq_respiratoria +
                        pa_diastolica +
                        pa_sistolica +
                        sat_o2 +
                        temperatura +
                        faixa_etaria +
                        setor2,
                    data = train,
                    method = "gbm",
                    trControl = cv,
                    tuneLength = 2,
                    metric = 'logLoss',
                    verbose = FALSE)

gbm
gbm$finalModel

y3 <- predict(gbm,
              newdata = test)

M_gbm <- confusionMatrix(y3,
                         test$alta.motivo,
                         positive = 'Obito')



########## Comparando os modelos
# Compare model performances using resample()
models_compare <- caret::resamples(list(RF=rf, GLM=bin, GBM=gbm),
                            positive='Obito')

# resumo das performances
summary(models_compare, positive='Obito')

# box plots comparando os modelos
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(models_compare, scales=scales)





########################################################################
# Extreme Gradient Boosting Machine - xgboost
########################################################################

# selecionando features
features <- setdiff(names(train),
                    c("pa_media","idade","setor","alta.motivo","alta.motivo2"))
features

# Preparando as features para one-hot-encoding
treatplan <- vtreat::designTreatmentsZ(train, features, verbose = FALSE)
treatplan

# Criando as novas features
new_vars <- treatplan %>%
  magrittr::use_series(scoreFrame) %>%
  dplyr::filter(code %in% c("clean", "lev")) %>%
  magrittr::use_series(varName)

# Preparando o dataset treino
features_train <- vtreat::prepare(treatplan,
                                  train,
                                  varRestriction = new_vars) %>%
    as.matrix()
head(features_train)



response_train <- train$alta.motivo2
head(response_train)


# Preparando o dataset teste
features_test <- vtreat::prepare(treatplan,
                                 test,
                                 varRestriction = new_vars) %>%
    as.matrix()
response_test <- test$alta.motivo2



dim(features_train)
dim(features_test)


# XGBoost
library(xgboost)
set.seed(123)

# parameter list
params <- list(
    eta = 0.01,
    max_depth = 4,
    subsample = 0.75,
    colsample_bytree = 1,
    gamma = 0.5
)

set.seed(123456)
xgb.fit1 <-xgboost(
    params = params,
  data = features_train,
  label = as.character(response_train),
  nrounds = 2999,
 # nfold = 5,
  objective = "reg:logistic",
  verbose = 0
)
xgb.fit1

evaluation <- data.frame(xgb.fit1$evaluation_log)
# get number of trees that minimize error
evaluation %>%
  dplyr::summarise(
    ntrees.train = which(train_rmse == min(train_rmse))[1],
    rmse.train   = min(train_rmse)
    )



importance_matrix <- xgb.importance(model = xgb.fit1)
xgb.plot.importance(importance_matrix,
                    top_n = 6,
                    measure = "Gain")

## Predição do modelo - prob
pred.XG <- predict(xgb.fit1, features_test)

## Predição do modelo - classe
y.XG <- ifelse(pred.XG > .5,
               'Obito',
               'Melhorado')
y.XG <- as.factor(y.XG)

M_XG <- confusionMatrix(y.XG,
                        test$alta.motivo,
                        positive = 'Obito')

M_XG



########################################################################
### LIME E SHAP
########################################################################
# selecionando dois exemplos para predição local.
local_obs <- test[1:2,]
local_obs_onehot <- vtreat::prepare(treatplan,
                                    local_obs,
                                    varRestriction = new_vars)

#####LIME
library(lime)
explainer <- lime(data.frame(features_train),
                  xgb.fit1)
explanation <- explain(local_obs_onehot,
                       explainer,
                       n_features = 5)
plot_features(explanation)



##### SHAP
library("SHAPforxgboost")
shap_values <- shap.values(xgb_model = xgb.fit1,
                           X_train = features_train)

shap.plot.summary.wrap1(xgb.fit1,
                        X = features_train)





################## GAM #################################
train$faixa_etaria_lev_x_lt_eq_55_anos <-features_train[,6]
train$faixa_etaria_lev_x_gt_55_anos <-features_train[,7]
train$setor2_lev_x_Enfermaria <-features_train[,8]
train$setor2_lev_x_UTI <-features_train[,9]

test$faixa_etaria_lev_x_lt_eq_55_anos <-features_test[,6]
test$faixa_etaria_lev_x_gt_55_anos <-features_test[,7]
test$setor2_lev_x_Enfermaria <-features_test[,8]
test$setor2_lev_x_UTI <-features_test[,9]

gam <- caret::train(alta.motivo ~ freq_respiratoria +
                        pa_diastolica +
                        pa_sistolica +
                        sat_o2 +
                        temperatura +
                        faixa_etaria_lev_x_lt_eq_55_anos +
                        setor2_lev_x_Enfermaria,
                        #setor2_lev_x_UTI +
                        #faixa_etaria_lev_x_gt_55_anos,
                    data = train,
                    method = "gam",
                    trControl = cv,
                    tuneLength = 2,
                    metric = 'logLoss')

gam
gam$finalModel

y.gam <- predict(gam,
                 newdata = test)

M_gam <- confusionMatrix(y.gam,
                test$alta.motivo,
                positive = 'Obito')

varimp <- varImp(gam)
plot(varimp, main="Variable Importance")



##################### Comparando os modelos
metrics <- data.frame(Modelo = c('GLM', 'TREE','RF','GBM','XGBoost','GAM'),
                          Acuracia = c(M_logistic$overall[1],M_tree$overall[1],M_rf$overall[1],M_gbm$overall[1],M_XG$overall[1],M_gam$overall[1]),
                      Kappa = c(M_logistic$overall[2],M_tree$overall[2],M_rf$overall[2],M_gbm$overall[2],M_XG$overall[2],M_gam$overall[2]),
                      Sensibilidade = c(M_logistic$byClass[1],M_tree$byClass[1],M_rf$byClass[1],M_gbm$byClass[1],M_XG$byClass[1],M_gam$byClass[1]),
                      Especificidade=c(M_logistic$byClass[2],M_tree$byClass[2],M_rf$byClass[2],M_gbm$byClass[2],M_XG$byClass[2],M_gam$byClass[2]),
                      Precision=c(M_logistic$byClass[5],M_tree$byClass[5],M_rf$byClass[5],M_gbm$byClass[5],M_XG$byClass[5],M_gam$byClass[5]),
                      F1 = c(M_logistic$byClass[7],M_tree$byClass[7],M_rf$byClass[7],M_gbm$byClass[7],M_XG$byClass[7],M_gam$byClass[7])
                      )

metrics
```



# Peso de Evidência

```{R woe}
rm(list=ls())
library(tidyverse)
library(scorecard)
##Carregando os dados
data('germancredit')

## Salvando os dados em um novo df
dados  <-  germancredit %>%
    as_tibble()

#replace '.' in variable names not compatible with f_train_lasso
vars  <-  names(dados) %>%
    str_replace_all( '\\.', '_')

names(dados) <- vars

# convert response factor variable to dummy variable

dados  <-  dados %>%
    mutate( creditability = ifelse( creditability == 'bad', 1, 0 )
         , creditability = as.factor(creditability) )

head(dados$creditability)


DataExplorer::plot_missing(dados)

#### WoE
bins  <- woebin(dados,
                y = 'creditability')

## Quantidade de crédito tomado
bins$credit_amount
woebin_plot(bins$credit_amount)

## Quantidade de meses para pagar o empréstimo
bins$duration_in_month
woebin_plot(bins$duration_in_month)

## Status do imóvel
bins$housing
woebin_plot(bins$housing)

## Aplicando as partições das features
dados_woe  <- woebin_ply( dados, bins ) %>%
    as_tibble()

names(dados_woe)
head(dados_woe)


##### Partição dos dados

set.seed(12339)
intrain <- caret::createDataPartition(y = dados_woe$creditability,
                                      p = 0.75,
                                      list = FALSE)
train <- dados_woe[intrain, ]
test <- dados_woe[-intrain, ]


#### Ajustando um modelo


bin <- glm(creditability ~ .,
                    data = train,
                    family = 'binomial')

## Predição - prob
y1 <- predict(bin,
              newdata = test,
              type = 'response')

## Predição - classes
test$pred <- ifelse(y1 > 0.5,
                     1,0)

library(SDMTools)
t1 <- confusion.matrix(test$creditability,
                       test$pred)

t1

tn <- t1[1]
fp <- t1[2]
fn <- t1[3]
tp <- t1[4]

## Calculando a sensibilidade e especificidade
sensibilidade <- tp/(tp + fn)
especificidade <- tn/(tn + fp)
sensibilidade;especificidade



########### Curva ROC
library(pROC)
rocobj <- roc(test$creditability,
              y1)

    gl <- ggroc(rocobj, legacy.axes = TRUE,color='#d07530')
    auc <- round(rocobj$auc,4)
    temp <- paste('AUC=', auc)
    gl<-gl+ annotate("text", x = .75, y = .25,colour = "#d07530", size=6, label= temp, parse=TRUE)


    gl + xlab("1-Especificidade") + ylab("Sensibilidade") +
      geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color='#d07530', linetype="dashed")
```


# Análise do ponto de corte - classificação binária

```{r cutoff}
rm(list=ls())
dados<-read.csv('predictions_validacao.csv',
                h=T,
                sep=',')

## Considerando que cometer o erro `FN` é 10 vezes mais "grave" que o erro `FP`.


# função custo
source("f_nao_balanceada.R")

## Matriz de confusão com ponto de corte default
cm_info <- ConfusionMatrixInfo(data = dados,
                               predict = "predictions_prob",
                               actual = "discharge_reason",
                               cutoff = .5 )
#cm_info$plot


### Definindo penalidade para cada erro
cost_fp <- 10
cost_fn <- 50
## Fazendo curva e escolhendo ponto de corte com base na função custo
roc_info <- ROCInfo(data = cm_info$data,
                    predict = "predict",
                    actual = "actual",
                    cost.fp = cost_fp,
                    cost.fn = cost_fn)
roc_info$cutoff

grid.draw(roc_info$plot)


cm_info <- ConfusionMatrixInfo(data = dados,
                               predict = "predictions_prob",
                               actual = "discharge_reason",
                               cutoff = roc_info$cutoff)

cm_info



# Comparação dos pontos de corte


## Ponto de corte $0.5$

### Predição classe
dados$prediction2<-ifelse(dados$predictions_prob>0.5,1,0)
### Acurácia
ac<-mean(dados$prediction2 == dados$discharge_reason)
paste0('Acurácia=',round(ac,4))

### Matriz de confusão
library(SDMTools)
t1<-confusion.matrix(dados$discharge_reason, dados$prediction2)
t1

### Definindo as estimativas de erro e acerto
tn <- t1[1]
fp <- t1[2]
fn <- t1[3]
tp <- t1[4]

TP_.5 <- tp/(tp + fn)
TN_.5 <- tn/(tn + fp)
FP_.5 <- fp/(fp + tn)
FN_.5 <- fn/(fn + tp)


##Ponto de corte $`r (roc_info$cutoff)`$

### Predição classe
dados$pred3<-ifelse(dados$predictions_prob>roc_info$cutoff, 1, 0)
### Acurácia
ac_.03<-mean(dados$pred3 == dados$discharge_reason)
paste0('Acurácia=',round(ac_.03,4))

### Matriz de confusão
library(SDMTools)
t2<-confusion.matrix(dados$discharge_reason,dados$pred3)
t2

tn <- t2[1]
fp <- t2[2]
fn <- t2[3]
tp <- t2[4]

TP_.03 <- tp/(tp + fn)
TN_.03 <- tn/(tn + fp)
FP_.03 <- fp/(fp + tn)
FN_.03 <- fn/(fn + tp)

## Comparando as medidas
matriz_c1<-matrix(c(TP_.5,TN_.5,FP_.5,FN_.5,TP_.03,TN_.03,FP_.03,FN_.03),
                  ncol = 2, byrow = F)
colnames(matriz_c1) <- c('Ponto de corte = 0.5',
                         paste0('Ponto de corte = ', roc_info$cutoff))

rownames(matriz_c1) <- c('Verdadeiro Positivo','Verdadeiro Negativo',
                       'Falso Positivo','Falso negativo')

matriz_c1


```
